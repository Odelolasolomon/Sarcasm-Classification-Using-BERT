{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "405Z6PmwLY7F"
   },
   "source": [
    "# Sarcasm Detection Using BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Google released the Bidirectional Encoder Representations from Transformers (BERT) model in 2018. It consists of stacked encoders of the transformer model released in 2017 and is pretrained on masked language modeling and next-sentence prediction tasks. It has seen massive success in modeling linguistic and semantic features in NLP applications. As a result, BERT has been successfully used for question answering, multigenre classification of text, and sentence completion tasks.\n",
    "\n",
    "In this project, we'll fine-tune the BERT model to detect sarcastic tweets. To do this, we'll use pandas and NumPy for manipulating the dataset. We'll also use the seaborn and Matplotlib libraries for creating visualizations and Keras and TensorFlow for implementing deep learning. Finally, we'll use the scikit-learn library to evaluate the model and compute its classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n this task, you’ll start by importing the Python modules used in the project. To complete this task, import the following libraries:\n",
    "\n",
    "pandas: This package is used for data manipulation and analysis.\n",
    "seaborn: This library is required for plotting confusion matrices as heatmaps.\n",
    "numpy: This package is required for number crunching in Python.\n",
    "tensorflow: This package is required for the training and inference of deep learning models.\n",
    "re: This module is used to preprocess the text data.\n",
    "tensorflow_hub: This library is required for access to the pretrained BERT model.\n",
    "tensorflow-text: This library is used in the preprocessing model from the TensorFlow Hub.\n",
    "optimization: This is a submodule of the official.nlp package, which provides methods for building machine learning projects in TensorFlow. It is required for creating the AdamW optimizer.\n",
    "pyplot: This is a submodule of the matplotlib library and is required for plotting the training curves.\n",
    "rcParams: This method is from the matplotlib module and is required for setting the plot size.\n",
    "keras: This package is required for creating the deep learning model using high-level functionality.\n",
    "Dense: This is a submodule of the keras.layers package and is required for creating dense classification layers in the deep learning model.\n",
    "model_from_json: This is a method of the tensorflow.keras.models package and is required for loading the trained model.\n",
    "math: This module is used for mathematical operations in Python.\n",
    "classification_report and confusion_matrix: These modules are from the sklearn.metrics package and are required for model evaluation.\n",
    "os: This module is used to hide warnings.\n",
    "Note: Since a GPU will not be used for this project, the notebook can be configured to hide exceptions by passing the following two commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTzKONdeLyLB",
    "outputId": "ffdfd81e-0141-4c08-83f2-1f72b1b48a40"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from official.nlp import optimization \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import math\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is usually to load the data and split it into training and test sets. In this case, the splitting has already been done. The dataset is made available as three files named train.csv, test.csv, and validate.csv in the /usercode directory. Each of the three files has two columns named text and labels. The text column contains the text of tweets, while the label column indicates if the tweet is sarcastic or not.\n",
    "\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "Load the text column of the three CSV files into DataFrames named X_train, X_test, and X_valid.\n",
    "Load the labels column of the three CSV files into DataFrames named Y_train, Y_test, and Y_valid.\n",
    "Display the X_train DataFrame using the DataFrame.head() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gVMvX3I3Bfe",
    "outputId": "5b28d659-c65d-4f21-fcf6-9462fc96b4ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; thanks for showing up for our appointme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haha .  # lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love waiting &lt;num&gt; min for a cab - such shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22 super funny quotes # funnyquotes  # funnysa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goog morning  # sorrynotsorry # morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  <user> thanks for showing up for our appointme...\n",
       "1                                      haha .  # lol\n",
       "2  i love waiting <num> min for a cab - such shor...\n",
       "3  22 super funny quotes # funnyquotes  # funnysa...\n",
       "4            goog morning  # sorrynotsorry # morning"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./usercode/train.csv')\n",
    "test = pd.read_csv('./usercode/test.csv')\n",
    "val = pd.read_csv('./usercode/validate.csv')\n",
    "X_train = train[[\"text\"]].copy()\n",
    "X_test = test[[\"text\"]].copy()\n",
    "X_val = val[[\"text\"]].copy()\n",
    "Y_train = train[[\"labels\"]].copy()\n",
    "Y_test = test[[\"labels\"]].copy()\n",
    "Y_val = val[[\"labels\"]].copy()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been loaded, preprocess the tweets so that they:\n",
    "\n",
    "Include only lowercase, alphanumeric characters.\n",
    "Are of the string data type.\n",
    "Do not contain the rt (retweet) tag.\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "Define the preprocess function as follows:\n",
    "Use the astype() method to convert the data type of the text column to string data type.\n",
    "Use the lower() function within the apply() method to convert the text column to lowercase.\n",
    "Use the sub() method of the re package within the apply() method to remove non-alphanumeric characters from the text column.\n",
    "Remove the retweet tag, rt, from the text.\n",
    "Use the preprocess function to preprocess the text of the tweets in the X_train, X_val, and X_test DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kx206x0RqBGi"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "  data = data.astype(str)\n",
    "  data = data.apply(lambda x: x.lower())\n",
    "  data = data.apply((lambda x: re.sub('[^a-zA-Z0-9\\s]','',x)))\n",
    "\n",
    "  for idx,row in enumerate(data):\n",
    "      row = row.replace('rt',' ')\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNXVzD9JBtW3",
    "outputId": "60938687-ee25-4006-9c7d-00e3699fffed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user thanks for showing up for our appointment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haha    lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love waiting num min for a cab  such shortag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22 super funny quotes  funnyquotes   funnysayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goog morning   sorrynotsorry  morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  user thanks for showing up for our appointment...\n",
       "1                                        haha    lol\n",
       "2  i love waiting num min for a cab  such shortag...\n",
       "3  22 super funny quotes  funnyquotes   funnysayi...\n",
       "4              goog morning   sorrynotsorry  morning"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"text\"] = preprocess(X_train[\"text\"])\n",
    "X_val[\"text\"] = preprocess(X_val[\"text\"])\n",
    "X_test[\"text\"] = preprocess(X_test[\"text\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Choose the Model and its Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll choose a model and its preprocessor from TensorFlow Hub. Each encoder requires a specific preprocessing layer that is compatible with it.\n",
    "\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "Clear the keras backend using keras.backend.clear_session().\n",
    "Declare the following parameters:\n",
    "encoder_url: This is the URL of the BERT model page at TensorFlow Hub.\n",
    "preprocessor_url: This is the URL of the preprocessor for the chosen encoder from TensorFlow Hub. The preprocessor required for each model is mentioned in the “Usage” section of the model’s page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h8JJQ6Jxocu6"
   },
   "outputs": [],
   "source": [
    "#Use the following piece of code to clear the backend, and create the model and encoder:\n",
    "keras.backend.clear_session()\n",
    "\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\"\n",
    "preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Create the Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll create the classification model that will take the text of the tweets as input and produce class predictions as outputs.\n",
    "\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "Write a function for building the classifier that includes the following parts:\n",
    "An input layer with the name text.\n",
    "A preprocessor block created using the hub.KerasLayer() method. This method requires the URL of the preprocessing model as input:\n",
    "Use the preprocessor_url chosen in Task 4.\n",
    "A BERT encoder retrieved from TensorFlow Hub, using the hub.KerasLayer() method. This method requires the URL of the previously chosen BERT model as input:\n",
    "Use the encoder_url chosen in Task 4.\n",
    "A pooling layer where pooled outputs are extracted from the encoder.\n",
    "A Dropout layer.\n",
    "A Dense output layer that produces the predictions.\n",
    "Use the function to build a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Hpg6ahlMX2fW"
   },
   "outputs": [],
   "source": [
    "#Use the following definition of the function for building the classifier:\n",
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(preprocessor_url, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(encoder_url, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.2)(net)\n",
    "  net = tf.keras.layers.Dense(2, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfrMfVa0YPvP",
    "outputId": "af9a1303-a790-4cae-c726-9e01e643a73a"
   },
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Initialize the Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll initialize the parameters and methods used for training the model. To complete the task, perform the following steps:\n",
    "\n",
    "Create a binary cross-entropy loss using tf.keras.losses.BinaryCrossentropy().\n",
    "Create the binary accuracy metric for model evaluation during training using tf.metrics.BinaryAccuracy().\n",
    "Declare the following parameters:\n",
    "epochs: This is the number of epochs for fine-tuning the model.\n",
    "batch_size: This is the batch size needed for training.\n",
    "steps_per_epoch: This is the number of steps per epoch. It is given by the number of rows in the training dataset divided by the batch size.\n",
    "num_train_steps: This is the total number of steps the model will train for, given by the product of epochs and steps_per_epoch.\n",
    "num_warmup_steps: This is the number of steps the optimizer will take to increase its learning rate from zero to the value specified. It will be 10% of the number of training steps.\n",
    "init_lr: This is the initial learning rate of the optimizer.\n",
    "Create the optimizer using optimization.create_optimizer(). This method takes the init_lr, num_train_steps, and num_warmup_steps parameters, defined in the previous step, as input. Additionally, provide the following parameter:\n",
    "optimizer_type: This is the type of optimizer that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A2boq7BeZCjM"
   },
   "outputs": [],
   "source": [
    "epochs =  4\n",
    "batch_size = 64\n",
    "steps_per_epoch = math.floor(X_train.shape[0]/batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "init_lr = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OMHS00clZHlc"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "            num_train_steps=num_train_steps, \n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type='adamw')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Load Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train the model, skip this Task. If you want to load the trained model, do this Task and skip Task 8 and 9.\n",
    "\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "The model is available in the current directory as a model.json file. The model weights are also given as a model.h5 file.\n",
    "Read the JSON file into an object.\n",
    "Use this object to load the model using the model_from_json() method from tensorflow.keras.models. This method accepts the following parameters:\n",
    "json_string: This is the object read from the JSON file.\n",
    "custom_objects: A dictionary mapping names to classes or functions to be considered during deserialization.\n",
    "Use model.load_weights() to load weights from the .h5 file. This function will require the path of the model.h5 file as a parameter.\n",
    "Compile the model using model.compile(). This method will take the optimizer, loss, and metrics parameters that were just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqhdWLbqaC22",
    "outputId": "8c258ad1-025a-4b38-d931-22b9ae71c7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('usercode/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "classifier_model = model_from_json(loaded_model_json, custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "\n",
    "classifier_model.load_weights(\"usercode/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_LxeNU9FZpn-"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll evaluate the model on the test set and get its accuracy, loss, and predictions. To complete the task, perform the following steps:\n",
    "\n",
    "Use the evaluate() method of Keras on the classifier_model to get the loss and accuracy on the test set. This method accepts the following inputs:\n",
    "x: These are the input sequences, i.e., the text column of the testing dataset.\n",
    "y: These are one-hot encoded vectors of the target labels.\n",
    "Use the predict() method of Keras to make class predictions. This method takes the input sequence as input and outputs class probabilities. To convert these probabilities into classes, use the np.argmax() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eDyHOtUhTP5",
    "outputId": "7fd599b2-575e-4c68-c02f-76ea2a39241d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/76 [..............................] - ETA: 1:02 - loss: 0.5291 - binary_accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/76 [..............................] - ETA: 9s - loss: 0.4362 - binary_accuracy: 0.7969  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/76 [>.............................] - ETA: 9s - loss: 0.4944 - binary_accuracy: 0.7396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/76 [>.............................] - ETA: 9s - loss: 0.4578 - binary_accuracy: 0.7656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/76 [>.............................] - ETA: 8s - loss: 0.4859 - binary_accuracy: 0.7563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/76 [=>............................] - ETA: 8s - loss: 0.4809 - binary_accuracy: 0.7656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/76 [=>............................] - ETA: 8s - loss: 0.4882 - binary_accuracy: 0.7634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/76 [==>...........................] - ETA: 8s - loss: 0.4789 - binary_accuracy: 0.7734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/76 [==>...........................] - ETA: 8s - loss: 0.4708 - binary_accuracy: 0.7778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/76 [==>...........................] - ETA: 7s - loss: 0.4769 - binary_accuracy: 0.7781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/76 [===>..........................] - ETA: 7s - loss: 0.4807 - binary_accuracy: 0.7756\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/76 [===>..........................] - ETA: 7s - loss: 0.4739 - binary_accuracy: 0.7734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/76 [====>.........................] - ETA: 7s - loss: 0.4742 - binary_accuracy: 0.7764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/76 [====>.........................] - ETA: 7s - loss: 0.4832 - binary_accuracy: 0.7679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/76 [====>.........................] - ETA: 7s - loss: 0.4866 - binary_accuracy: 0.7646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/76 [=====>........................] - ETA: 7s - loss: 0.4855 - binary_accuracy: 0.7656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/76 [=====>........................] - ETA: 7s - loss: 0.4867 - binary_accuracy: 0.7647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/76 [======>.......................] - ETA: 6s - loss: 0.4956 - binary_accuracy: 0.7587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/76 [======>.......................] - ETA: 6s - loss: 0.4870 - binary_accuracy: 0.7664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/76 [======>.......................] - ETA: 6s - loss: 0.4912 - binary_accuracy: 0.7578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/76 [=======>......................] - ETA: 6s - loss: 0.4875 - binary_accuracy: 0.7634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/76 [=======>......................] - ETA: 6s - loss: 0.4806 - binary_accuracy: 0.7670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/76 [========>.....................] - ETA: 6s - loss: 0.4788 - binary_accuracy: 0.7663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/76 [========>.....................] - ETA: 6s - loss: 0.4719 - binary_accuracy: 0.7708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/76 [========>.....................] - ETA: 6s - loss: 0.4764 - binary_accuracy: 0.7688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/76 [=========>....................] - ETA: 5s - loss: 0.4748 - binary_accuracy: 0.7704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/76 [=========>....................] - ETA: 5s - loss: 0.4750 - binary_accuracy: 0.7731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/76 [==========>...................] - ETA: 5s - loss: 0.4758 - binary_accuracy: 0.7734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/76 [==========>...................] - ETA: 5s - loss: 0.4906 - binary_accuracy: 0.7629\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/76 [==========>...................] - ETA: 5s - loss: 0.5167 - binary_accuracy: 0.7510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/76 [===========>..................] - ETA: 5s - loss: 0.5412 - binary_accuracy: 0.7369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/76 [===========>..................] - ETA: 5s - loss: 0.5654 - binary_accuracy: 0.7266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/76 [============>.................] - ETA: 5s - loss: 0.5922 - binary_accuracy: 0.7140\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/76 [============>.................] - ETA: 4s - loss: 0.5913 - binary_accuracy: 0.7132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/76 [============>.................] - ETA: 4s - loss: 0.5925 - binary_accuracy: 0.7125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/76 [=============>................] - ETA: 4s - loss: 0.5863 - binary_accuracy: 0.7170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/76 [=============>................] - ETA: 4s - loss: 0.5842 - binary_accuracy: 0.7179\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/76 [==============>...............] - ETA: 4s - loss: 0.5765 - binary_accuracy: 0.7237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/76 [==============>...............] - ETA: 4s - loss: 0.5754 - binary_accuracy: 0.7228\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/76 [==============>...............] - ETA: 4s - loss: 0.5726 - binary_accuracy: 0.7250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/76 [===============>..............] - ETA: 4s - loss: 0.5678 - binary_accuracy: 0.7287\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/76 [===============>..............] - ETA: 4s - loss: 0.5670 - binary_accuracy: 0.7307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/76 [===============>..............] - ETA: 3s - loss: 0.5616 - binary_accuracy: 0.7333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/76 [================>.............] - ETA: 3s - loss: 0.5544 - binary_accuracy: 0.7372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/76 [================>.............] - ETA: 3s - loss: 0.5490 - binary_accuracy: 0.7403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/76 [=================>............] - ETA: 3s - loss: 0.5480 - binary_accuracy: 0.7405\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/76 [=================>............] - ETA: 3s - loss: 0.5472 - binary_accuracy: 0.7400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/76 [=================>............] - ETA: 3s - loss: 0.5446 - binary_accuracy: 0.7415\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/76 [==================>...........] - ETA: 3s - loss: 0.5446 - binary_accuracy: 0.7430\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/76 [==================>...........] - ETA: 3s - loss: 0.5398 - binary_accuracy: 0.7462\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/76 [===================>..........] - ETA: 2s - loss: 0.5379 - binary_accuracy: 0.7475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r52/76 [===================>..........] - ETA: 2s - loss: 0.5345 - binary_accuracy: 0.7494\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/76 [===================>..........] - ETA: 2s - loss: 0.5330 - binary_accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/76 [====================>.........] - ETA: 2s - loss: 0.5309 - binary_accuracy: 0.7506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/76 [====================>.........] - ETA: 2s - loss: 0.5276 - binary_accuracy: 0.7528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/76 [=====================>........] - ETA: 2s - loss: 0.5264 - binary_accuracy: 0.7522\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/76 [=====================>........] - ETA: 2s - loss: 0.5255 - binary_accuracy: 0.7516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/76 [=====================>........] - ETA: 2s - loss: 0.5271 - binary_accuracy: 0.7495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/76 [======================>.......] - ETA: 2s - loss: 0.5270 - binary_accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/76 [======================>.......] - ETA: 1s - loss: 0.5255 - binary_accuracy: 0.7510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/76 [=======================>......] - ETA: 1s - loss: 0.5259 - binary_accuracy: 0.7510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/76 [=======================>......] - ETA: 1s - loss: 0.5248 - binary_accuracy: 0.7515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/76 [=======================>......] - ETA: 1s - loss: 0.5252 - binary_accuracy: 0.7505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/76 [========================>.....] - ETA: 1s - loss: 0.5262 - binary_accuracy: 0.7490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/76 [========================>.....] - ETA: 1s - loss: 0.5237 - binary_accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/76 [=========================>....] - ETA: 1s - loss: 0.5203 - binary_accuracy: 0.7519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/76 [=========================>....] - ETA: 1s - loss: 0.5193 - binary_accuracy: 0.7523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r68/76 [=========================>....] - ETA: 0s - loss: 0.5181 - binary_accuracy: 0.7537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/76 [==========================>...] - ETA: 0s - loss: 0.5165 - binary_accuracy: 0.7545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/76 [==========================>...] - ETA: 0s - loss: 0.5128 - binary_accuracy: 0.7563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/76 [===========================>..] - ETA: 0s - loss: 0.5122 - binary_accuracy: 0.7557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r72/76 [===========================>..] - ETA: 0s - loss: 0.5088 - binary_accuracy: 0.7578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/76 [===========================>..] - ETA: 0s - loss: 0.5074 - binary_accuracy: 0.7590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r74/76 [============================>.] - ETA: 0s - loss: 0.5059 - binary_accuracy: 0.7593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/76 [============================>.] - ETA: 0s - loss: 0.5048 - binary_accuracy: 0.7596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r76/76 [==============================] - 10s 117ms/step - loss: 0.5042 - binary_accuracy: 0.7601\n",
      "Loss:  0.5041567087173462\n",
      "Accuracy:  0.7600663900375366\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(X_test, pd.get_dummies(Y_test[\"labels\"]))\n",
    "\n",
    "print('Loss: ', loss)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKKSAX6iDj3z",
    "outputId": "54cca961-7ce0-4970-a896-285d0e96a547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/76 [..............................] - ETA: 36s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/76 [..............................] - ETA: 9s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/76 [>.............................] - ETA: 9s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/76 [>.............................] - ETA: 9s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/76 [>.............................] - ETA: 9s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/76 [=>............................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/76 [=>............................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/76 [==>...........................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/76 [==>...........................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/76 [==>...........................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/76 [===>..........................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/76 [===>..........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/76 [====>.........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/76 [====>.........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/76 [====>.........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/76 [=====>........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/76 [=====>........................] - ETA: 7s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/76 [======>.......................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/76 [======>.......................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/76 [======>.......................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/76 [=======>......................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/76 [=======>......................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/76 [========>.....................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/76 [========>.....................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/76 [========>.....................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26/76 [=========>....................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/76 [=========>....................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28/76 [==========>...................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/76 [==========>...................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/76 [==========>...................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/76 [===========>..................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32/76 [===========>..................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/76 [============>.................] - ETA: 5s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/76 [============>.................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/76 [============>.................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/76 [=============>................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/76 [=============>................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r38/76 [==============>...............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/76 [==============>...............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/76 [==============>...............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/76 [===============>..............] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r42/76 [===============>..............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/76 [===============>..............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44/76 [================>.............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/76 [================>.............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46/76 [=================>............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/76 [=================>............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/76 [=================>............] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/76 [==================>...........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/76 [==================>...........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/76 [===================>..........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r52/76 [===================>..........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/76 [===================>..........] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/76 [====================>.........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/76 [====================>.........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/76 [=====================>........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r57/76 [=====================>........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r58/76 [=====================>........] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59/76 [======================>.......] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60/76 [======================>.......] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r61/76 [=======================>......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/76 [=======================>......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/76 [=======================>......] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r64/76 [========================>.....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65/76 [========================>.....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r66/76 [=========================>....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/76 [=========================>....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r68/76 [=========================>....] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/76 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r70/76 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r71/76 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r72/76 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/76 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r74/76 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r75/76 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r76/76 [==============================] - 10s 128ms/step\n"
     ]
    }
   ],
   "source": [
    "actuals = Y_test[\"labels\"]\n",
    "Y_predicted = classifier_model.predict(X_test)\n",
    "predictions= np.argmax(Y_predicted,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11: Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll create a confusion matrix to display the class predictions in graphical form.\n",
    "\n",
    "To complete this task, perform the following steps:\n",
    "\n",
    "Create a confusion matrix using the confusion_matrix() method from sklearn. This method requires the actual and class predictions as arguments.\n",
    "Set the figure size using the plt.figure() method. This method accepts the argument figsize, which is a tuple of length 2.\n",
    "Display the confusion matrix using seaborn’s heatmap() method. This method accepts the following inputs:\n",
    "data: This matrix will be plotted as a heatmap.\n",
    "annot: This is a boolean that determines if the values of each cell will be printed in the heatmap.\n",
    "fmt: This string determines the format of the printed values.\n",
    "Label the y-axis as true and the x-axis as predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "MeUGoSHhD8Zl",
    "outputId": "c95b4f78-3b17-4ec5-9b23-3feed90fdb43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(20.72222222222222, 0.5, 'True')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(actuals, predictions)\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12: Generate the Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you’ll generate a classification report. To complete this task, perform the following steps:\n",
    "\n",
    "Use the classification_report() method from sklearn to generate a classification report. This method computes various classification metrics, such as accuracy, precision, recall, and F1-score. This function takes the following arguments:\n",
    "y_true: These are the actual labels from the dataset.\n",
    "y_pred: These are the predicted targets the classifier gives.\n",
    "target_names: This is a list of labels, i.e., the class names.\n",
    "Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOqZcD9PD_u0",
    "outputId": "ef5ac352-15fe-4a17-a9f6-948f15d2aaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-Sarcastic       0.82      0.77      0.79      1450\n",
      "    Sarcastic       0.68      0.75      0.71       959\n",
      "\n",
      "     accuracy                           0.76      2409\n",
      "    macro avg       0.75      0.76      0.75      2409\n",
      " weighted avg       0.77      0.76      0.76      2409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Non-Sarcastic', \"Sarcastic\"]\n",
    "print(classification_report(actuals, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz5H1Nxnhxuh"
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
